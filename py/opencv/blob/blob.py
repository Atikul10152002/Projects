import cv2
import math
import numpy as np
from enum import Enum


video = cv2.VideoCapture(1)

detector = cv2.SimpleBlobDetector_create()


class GripPipeline:
    """
    An OpenCV pipeline generated by GRIP.
    """

    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsv_threshold_hue = [0.0, 13.446519524618012]
        self.__hsv_threshold_saturation = [
            61.915467625899275, 138.106960950764]
        self.__hsv_threshold_value = [55.03597122302158, 255.0]

        self.hsv_threshold_output = None

        self.__mask_mask = self.hsv_threshold_output

        self.mask_output = None

        self.__rgb_threshold_input = self.mask_output
        self.__rgb_threshold_red = [38.98381294964029, 94.8132427843803]
        self.__rgb_threshold_green = [27.51798561151079, 90.48387096774194]
        self.__rgb_threshold_blue = [9.172661870503596, 66.67232597623091]

        self.rgb_threshold_output = None

        self.__blur_input = self.rgb_threshold_output
        self.__blur_type = BlurType.Median_Filter
        self.__blur_radius = 34.234234234234236

        self.blur_output = None

    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input,
                                                           self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Mask0:
        self.__mask_input = source0
        self.__mask_mask = self.hsv_threshold_output
        (self.mask_output) = self.__mask(self.__mask_input, self.__mask_mask)

        # Step RGB_Threshold0:
        self.__rgb_threshold_input = self.mask_output
        (self.rgb_threshold_output) = self.__rgb_threshold(self.__rgb_threshold_input,
                                                           self.__rgb_threshold_red, self.__rgb_threshold_green, self.__rgb_threshold_blue)

        # Step Blur0:
        self.__blur_input = self.rgb_threshold_output
        # (self.blur_output) = self.__blur(
        #     self.__blur_input, self.__blur_type, self.__blur_radius)
        self.final_output = self.__blur(
            self.__blur_input, self.__blur_type, self.__blur_radius)
        self.keypoint = detector.detect(self.final_output)

        self.imgkeypoints = cv2.drawKeypoints(self.final_output, self.keypoint, np.array(
            []), (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        
        cv2.imshow("blurr", self.imgkeypoints)

    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __mask(input, mask):
        """Filter out an area of an image using a binary mask.
        Args:
            input: A three channel numpy.ndarray.
            mask: A black and white numpy.ndarray.
        Returns:
            A three channel numpy.ndarray.
        """
        return cv2.bitwise_and(input, input, mask=mask)

    @staticmethod
    def __rgb_threshold(input, red, green, blue):
        """Segment an image based on color ranges.
        Args:
            input: A BGR numpy.ndarray.
            red: A list of two numbers the are the min and max red.
            green: A list of two numbers the are the min and max green.
            blue: A list of two numbers the are the min and max blue.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)
        return cv2.inRange(out, (red[0], green[0], blue[0]),  (red[1], green[1], blue[1]))

    @staticmethod
    def __blur(src, type, radius):
        """Softens an image using one of several filters.
        Args:
            src: The source mat (numpy.ndarray).
            type: The blurType to perform represented as an int.
            radius: The radius for the blur as a float.
        Returns:
            A numpy.ndarray that has been blurred.
        """
        if(type is BlurType.Box_Blur):
            ksize = int(2 * round(radius) + 1)
            return cv2.blur(src, (ksize, ksize))
        elif(type is BlurType.Gaussian_Blur):
            ksize = int(6 * round(radius) + 1)
            return cv2.GaussianBlur(src, (ksize, ksize), round(radius))
        elif(type is BlurType.Median_Filter):
            ksize = int(2 * round(radius) + 1)
            return cv2.medianBlur(src, ksize)
        else:
            return cv2.bilateralFilter(src, -1, round(radius), round(radius))


BlurType = Enum(
    'BlurType', 'Box_Blur Gaussian_Blur Median_Filter Bilateral_Filter')


Grip  = GripPipeline()

a = 0
while 1:
    a += 1
    check, frame = video.read()
    frame = cv2.resize(frame, (int(frame.shape[1]/2), int(frame.shape[0]/2)))

    Grip.process(frame)

    # imgkeypoints = cv2.drawKeypoints(frame, keypoints, np.array(
        # []), (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    contours = c.getContours(frame)
    c.findPart(contours)

    key = cv2.waitKey(1)
    if key == ord("q"):
        break

    # ? waitKey([, delay]) -> retval
    # * The function waitKey waits for a key event infinitely or milliseconds, when the argument is positive
    k = cv2.waitKey(5) & 0xFF

video.release()
cv2.destroyAllWindows()

# ? Releases the Video Capture
cap.release()
